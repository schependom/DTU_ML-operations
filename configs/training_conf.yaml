# Training hyperparameters configuration

learning_rate: 0.001
batch_size: 32
epochs: 10

optimizer: adam

loss_fn:
  _target_: torch.nn.CrossEntropyLoss

logging:
  log_interval: 100
  save_path: "models/model.pth"
  figure_path: "reports/figures/training_statistics.png"

data:
  batch_size: 32

model_checkpoint: "models/model.pth"
